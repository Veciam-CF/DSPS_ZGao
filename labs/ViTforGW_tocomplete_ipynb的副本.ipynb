{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Veciam-CF/DSPS_ZGao/blob/main/labs/ViTforGW_tocomplete_ipynb%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import rescale\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "import pylab as plt\n",
        "\n",
        "DIRECTLYFROMGRAVITYSPY = False"
      ],
      "metadata": {
        "id": "FSatv31GbrIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an-8nvV2bmRn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_and_crop_image(filename, x, y):\n",
        "    \"\"\"Read in a crop part of image you want to keep\n",
        "\n",
        "    Parameters\n",
        "        filename (str):\n",
        "            the file you would like to pixelize\n",
        "\n",
        "        x (float, list):\n",
        "            xrange of pixels to keep\n",
        "\n",
        "        y (float, list):\n",
        "            yrange of pixels to keep\n",
        "\n",
        "\n",
        "    Returns\n",
        "        image_data (`np.array):\n",
        "            this images is taken from rgb to gray scale\n",
        "            and then downsampled by the resolution.\n",
        "    \"\"\"\n",
        "    xmin = x[0]\n",
        "    xmax = x[1]\n",
        "    ymin = y[0]\n",
        "    ymax = y[1]\n",
        "    image_data = io.imread(filename)\n",
        "    image_data = image_data[xmin:xmax, ymin:ymax, :3]\n",
        "    return image_data\n",
        "\n",
        "\n",
        "def read_grayscale(filename, resolution=0.3, x=[66, 532], y=[105, 671],\n",
        "                   verbose=False):\n",
        "    \"\"\"Convert image from RGB to Gray, downsample\n",
        "\n",
        "    Parameters\n",
        "        filename (str):\n",
        "            the file you would like to pixelize\n",
        "\n",
        "        resolution (float, optional):\n",
        "            default: 0.3\n",
        "\n",
        "        verbose (bool, optional):\n",
        "            default: False\n",
        "\n",
        "    Returns\n",
        "        image_data (`np.array):\n",
        "            this images is taken from rgb to gray scale\n",
        "            and then downsampled by the resolution.\n",
        "    \"\"\"\n",
        "    image_data = read_and_crop_image(filename, x=x, y=y)\n",
        "\n",
        "    image_data = rgb2gray(image_data)\n",
        "    image_data = rescale(image_data, resolution, mode='constant',\n",
        "                         preserve_range='True', channel_axis=None)\n",
        "\n",
        "    #dim = int(reduce(lambda x, y: x * y, image_data.shape))\n",
        "    #image_data = np.reshape(image_data, (dim))\n",
        "    image_data = np.array(image_data, dtype='f')\n",
        "\n",
        "    return image_data\n",
        "\n",
        "\n",
        "def read_rgb(filename, resolution=0.3, x=[66, 532], y=[105, 671],\n",
        "             verbose=False):\n",
        "    \"\"\"Convert image from RGB to Gray, downsample\n",
        "\n",
        "    Parameters\n",
        "        filename (str):\n",
        "            the file you would like to pixelize\n",
        "\n",
        "        resolution (float, optional):\n",
        "            default: 0.3\n",
        "\n",
        "        verbose (bool, optional):\n",
        "            default: False\n",
        "\n",
        "    Returns\n",
        "        image_data (`np.array):\n",
        "            this images is taken from rgb to gray scale\n",
        "            and then downsampled by the resolution.\n",
        "    \"\"\"\n",
        "    image_data = read_and_crop_image(filename, x=x, y=y)\n",
        "    image_data = rescale(image_data, resolution, mode='constant',\n",
        "                         preserve_range='True', channel_axis=-1)\n",
        "    dim = int(reduce(lambda x, y: x * y, image_data[:, :, 0].shape))\n",
        "    image_data_r = np.reshape(image_data[:, :, 0], (dim))\n",
        "    image_data_g = np.reshape(image_data[:, :, 1], (dim))\n",
        "    image_data_b = np.reshape(image_data[:, :, 2], (dim))\n",
        "\n",
        "    return image_data_r, image_data_g, image_data_b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run the cell below to select your classes and read in teh images directly from GravitySpy"
      ],
      "metadata": {
        "id": "mGnLhVxAlXQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if DIRECTLYFROMGRAVITYSPY:\n",
        "  labels = []\n",
        "  imgs = np.zeros((2264, 140, 170))\n",
        "  j, k = 0, 0\n",
        "  for i,f in enumerate(glob(\"H1L1/Chirp/*\")):\n",
        "      #print(f)\n",
        "      if k == 264:\n",
        "          break\n",
        "      img = read_grayscale(f)\n",
        "      if i%100 == 0 :\n",
        "          plt.imshow(img)\n",
        "          plt.title(f\"Chirp {i} \")\n",
        "          plt.show()\n",
        "      imgs[j] = img\n",
        "      labels.append([\"chirp\"])\n",
        "      k += 1\n",
        "      j += 1\n",
        "  print(i)\n",
        "  k = 0\n",
        "  for i,f in enumerate(glob(\"H1L1/Low_Frequency_Burst/*\")) :\n",
        "      if k == 1000:\n",
        "          break\n",
        "      img = read_grayscale(f)\n",
        "      if i%100 == 0 :\n",
        "          plt.imshow(img)\n",
        "          plt.title(f\"Low_Frequency_Burst {i}\")\n",
        "          plt.show()\n",
        "\n",
        "      imgs[j] = img\n",
        "      labels.append([\"low_frequency_burst\"])\n",
        "      k += 1\n",
        "      j += 1\n",
        "  print(i,j,k)\n",
        "\n",
        "  k = 0\n",
        "  for i,f in enumerate(glob(\"H1L1/Koi_Fish/*\")) :\n",
        "      if k == 1000:\n",
        "          break\n",
        "      img = read_grayscale(f)\n",
        "      if i%100 == 0 :\n",
        "          plt.imshow(img)\n",
        "          plt.title(f\"koi_fish {i}\")\n",
        "          plt.show()\n",
        "\n",
        "      imgs[j] = img\n",
        "      labels.append([\"koi_fish\"])\n",
        "      k += 1\n",
        "      j += 1\n"
      ],
      "metadata": {
        "id": "ALKdI5yAbnql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run the two cells below to read the pre-made array of data"
      ],
      "metadata": {
        "id": "pYgRa--LlhDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not DIRECTLYFROMGRAVITYSPY:\n",
        "  labels = pd.read_csv(\"gw_labels.csv\", index_col=0)\n",
        "  labels"
      ],
      "metadata": {
        "id": "4UxyUN4UccgR",
        "outputId": "8a3d5217-932e-442e-a954-c5a1027a5605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'gw_labels.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3810889712.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mDIRECTLYFROMGRAVITYSPY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gw_labels.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gw_labels.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not DIRECTLYFROMGRAVITYSPY:\n",
        "  imgs = np.load(open(\"gw_imgs.npy\", \"rb\"))\n",
        "  imgs.shape\n",
        "#reshaping images with a new axis because vision transformers are commonly built for 3 axis images\n",
        "imgs = imgs[:,:,:,np.newaxis]\n",
        "imgs.shape"
      ],
      "metadata": {
        "id": "S2DYh662kMP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show a few images\n",
        "np.random.seed(302)\n",
        "for i in np.random.choice(imgs.shape[0], 10):\n",
        "  plt.imshow(imgs[i])\n",
        "  plt.title(labels.iloc[i])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "avFLhJeullpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhWN56lxoKj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Encode string labels into numerical format\n",
        "#label_encoder = LabelEncoder()\n",
        "#encoded_labels_sparse = label_encoder.fit_transform(labels)\n",
        "#sparse encoder makes a 1D label with numbers 0-n, use sparse_categorical_crossentropy loss\n",
        "\n",
        "# Convert to one-hot encoded format\n",
        "...\n",
        "...\n",
        "encoded_labels[:20], encoded_labels[-20:]\n",
        "#use categorical_crossentropy loss"
      ],
      "metadata": {
        "id": "B0d64nhneJte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTANT:\n",
        "# stratify: Perform the train-test split with same fraction of labels in training and testing - for imbalanced datasets\n",
        "# Shuffle the data because the labels are ordered!\n",
        "X_train, X_test, y_train, y_test = ....\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Show the mapping of original labels to encoded numbers\n",
        "print(\"\\nLabel encoding mapping:\")\n",
        "for i, label_name in enumerate(label_encoder.classes_):\n",
        "    print(f\"{label_name}: {i}\")"
      ],
      "metadata": {
        "id": "10U4xNYrhTuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "class PatchExtract(layers.Layer):\n",
        "    \"\"\"Extract patches from images.\"\"\"\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "class MinimalViT(keras.Model):\n",
        "    \"\"\"Minimal Vision Transformer for 140x170 images.\"\"\"\n",
        "    def __init__(self, image_size=(140, 170), patch_size=14, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Adjust to be divisible by patch_size\n",
        "        self.image_size = image_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (image_size[0] // patch_size) * (image_size[1] // patch_size)\n",
        "        self.embed_dim = 64\n",
        "\n",
        "        # Patch extraction and embedding\n",
        "        self.patch_extract = PatchExtract(patch_size)\n",
        "        self.patch_embed = layers.Dense(self.embed_dim)\n",
        "\n",
        "        # CLS token and position embeddings\n",
        "        self.cls_token = self.add_weight(\n",
        "            shape=(1, 1, self.embed_dim),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='cls_token'\n",
        "        )\n",
        "        self.pos_embed = self.add_weight(\n",
        "            shape=(1, self.num_patches + 1, self.embed_dim),\n",
        "            initializer='random_normal',\n",
        "            trainable=True,\n",
        "            name='pos_embed'\n",
        "        )\n",
        "\n",
        "        # Transformer encoder layers (corrected structure)\n",
        "        ...\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "        # Extract patches\n",
        "\n",
        "\n",
        "        # Embed patches\n",
        "\n",
        "\n",
        "        # Add CLS token\n",
        "        cls_tokens = tf.tile(self.cls_token, [batch_size, 1, 1])\n",
        "        x = tf.concat([cls_tokens, x], axis=1)  # (batch, num_patches+1, embed_dim)\n",
        "\n",
        "        # Add position embeddings\n",
        "\n",
        "        # Single transformer block logic\n",
        "        # Layer Normalization 1\n",
        "\n",
        "        # Multi-Head Self-Attention\n",
        "\n",
        "        # Layer Normalization 2 and MLP\n",
        "\n",
        "        # Use CLS token for classification\n",
        "\n",
        "\n",
        "        return self.head(x)\n"
      ],
      "metadata": {
        "id": "ZohJmMqzcalZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "num_classes = 3\n",
        "# Assuming your data is already loaded\n",
        "# X_train shape: (n_samples, 140, 170, 3) - now correct with 3 channels\n",
        "# y_train shape: (n_samples, 3) - one-hot encoded\n",
        "\n",
        "# 1. Create minimal ViT model\n",
        "# IMPORTANT: Set num_classes to 3, matching your dataset's actual number of classes\n",
        "model = ...\n",
        "\n",
        "# 2. Build with input shape\n",
        "# Input shape should now be (None, 140, 170, 3) as imgs_processed will have 3 channels\n",
        "model.build(...\n",
        "\n",
        "# 3. Compile\n",
        "# IMPORTANT: Change loss to 'categorical_crossentropy' because y_train is one-hot encoded\n",
        "model.compile(\n",
        "    ...\n",
        ")\n",
        "\n",
        "# 4. Train\n",
        "history = model.fit(\n",
        "  ...\n",
        ")\n",
        "\n",
        "# 5. Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {acc:.2%}\")\n",
        "\n",
        "# 6. Predict\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "gKuWxOARcyJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])"
      ],
      "metadata": {
        "id": "qXUYJ3GejRZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1980cfb1"
      },
      "source": [
        "# Convert model predictions from probabilities to class labels\n",
        "y_pred_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test back to original class labels for comparison\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Get class names from the label encoder for better readability in the matrix\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "print(\"Predicted classes sample:\", y_pred_classes[:10])\n",
        "print(\"True classes sample:\", y_true_classes[:10])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fde24c43"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usK-m-J2j9Na"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}